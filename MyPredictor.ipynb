{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cores:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#Predict smallest Number\n",
    "\n",
    "#!conda install -n mldds -c anaconda joblib\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action='once')\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "print(\"Cores: \", num_cores)\n",
    "\n",
    "from multiprocessing import JoinableQueue\n",
    "from threading import Thread\n",
    "\n",
    "import time\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# import tensorflow as tf\n",
    "# config = tf.ConfigProto( device_count = {'GPU': 0 , 'CPU': num_cores} )\n",
    "# sess = tf.Session(config=config) \n",
    "# keras.backend.set_session(sess)\n",
    "\n",
    "# import tensorflow as tf\n",
    "# config = tf.ConfigProto( device_count = {'GPU': 0 , 'CPU': num_cores} )\n",
    "# sess = tf.Session(config=config) \n",
    "\n",
    "# keras.backend.set_session(sess)\n",
    "# keras.backend.clear_session()\n",
    "\n",
    "\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from MyTotoResearchv4 import *\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, SGDRegressor, SGDClassifier, LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor, GradientBoostingClassifier\n",
    "from sklearn.svm import SVR\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, History\n",
    "import json as simplejson\n",
    "from keras import regularizers\n",
    "from sklearn import preprocessing\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllData(df):\n",
    "    drop_cols = ['T', 'D', 'N1','N2','N3','N4','N5','N6','N7','L','M','S','R','E','A','V' ,'J','U']\n",
    "    drop_cols = ['D', 'N1','N2','N3','N4','N5','N6','N7', 'Ph', 'il', 'age', 'dist', 'adia', 'sundist', 'sunadia' ]\n",
    "\n",
    "#     Ph         1521 non-null float64\n",
    "# il         1521 non-null float64\n",
    "# age        1521 non-null float64\n",
    "# dist       1521 non-null float64\n",
    "# adia       1521 non-null float64\n",
    "# sundist    1521 non-null float64\n",
    "# sunadia    1521 non-null float64\n",
    "\n",
    "#    drop_cols = ['T', 'D', 'M','S','R','E','A','V' ,'J','U']\n",
    "\n",
    "\n",
    "#    X = df.drop(drop_cols, axis=1)\n",
    "    \n",
    "    X = df[['L','M','S','R','E','A','V','age','il', 'dist', 'sundist']]\n",
    "#    X = df[['L','M','S','age','il', 'dist', 'sundist']]\n",
    "\n",
    "\n",
    "#    X = df[[ 'T','L','M','S','il', 'age', 'dist', 'adia', 'sundist', 'sunadia']]\n",
    "    X = df[['L','M','S', 'age','il', 'dist', 'adia', 'sundist', 'sunadia']]\n",
    "\n",
    "#    X = df[[ 'T','L','M','il', 'age', 'dist', 'adia', 'sundist', 'sunadia']]\n",
    "\n",
    "\n",
    "#     df1 = df[['N1','N2','N3','N4','N5','N6','N7']]\n",
    "#     X['smallest'] = df1.min(axis=1)\n",
    "#     X['biggest'] = df1.max(axis=1)\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def getSmallestN(df):\n",
    "    df1 = df[['N1','N2','N3','N4','N5','N6','N7']]\n",
    "    y = pd.DataFrame(index=df.index)\n",
    "    y['SN'] = df1.min(axis=1)\n",
    "    return y ;\n",
    "\n",
    "def getBiggestN(df):\n",
    "    df1 = df[['N1','N2','N3','N4','N5','N6','N7']]\n",
    "    y = pd.DataFrame(index=df.index)\n",
    "    y['LN'] = df1.max(axis=1)\n",
    "    return y ;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MyTotoResearch algo_no:  1\n",
      "1521\n",
      "      N1  N2  N3  N4  N5  N6  N7         D\n",
      "0      3  10  18  21  29  36  42  20040212\n",
      "1      6   8  22  39  40  41  45  20040216\n",
      "2      5   8  15  17  21  35  36  20040219\n",
      "3      6  20  21  23  28  38  39  20040223\n",
      "4      3  10  16  25  26  40  44  20040226\n",
      "5     14  20  22  25  27  28  29  20040301\n",
      "6      2   6   7  25  40  41  43  20040304\n",
      "7      2  17  18  19  21  42  44  20040308\n",
      "8     10  18  24  26  34  36  43  20040311\n",
      "9      1   9  13  16  32  35  45  20040315\n",
      "10     6  17  21  31  40  42  43  20040318\n",
      "11    16  21  22  23  27  28  35  20040322\n",
      "12     6  13  18  20  37  38  43  20040325\n",
      "13     1   2   6   7  19  24  32  20040329\n",
      "14     3   9  27  28  31  39  40  20040401\n",
      "15     4   7  12  13  15  16  33  20040405\n",
      "16     4  11  25  30  33  36  39  20040408\n",
      "17     2   8  10  16  29  32  37  20040412\n",
      "18     2   3   9  19  26  32  34  20040415\n",
      "19    10  15  18  26  36  39  45  20040419\n",
      "20     5   6   8  14  23  26  37  20040422\n",
      "21     7  15  18  24  25  37  41  20040426\n",
      "22     6  10  18  22  31  32  43  20040429\n",
      "23     3   4   9  12  20  33  37  20040503\n",
      "24     5  11  20  23  27  30  34  20040506\n",
      "25     2   6   8  16  19  21  41  20040510\n",
      "26    11  13  16  21  24  35  45  20040513\n",
      "27     2   6  10  13  17  21  28  20040517\n",
      "28    17  20  23  25  32  36  45  20040520\n",
      "29     6   7  16  21  33  40  44  20040524\n",
      "...   ..  ..  ..  ..  ..  ..  ..       ...\n",
      "1491   5   6  16  24  26  29  38  20180827\n",
      "1492   2   3  19  23  30  39  41  20180823\n",
      "1493   2   9  10  25  38  40  42  20180820\n",
      "1494  20  22  23  25  32  33  36  20180816\n",
      "1495   1   3   6  16  17  22  36  20180813\n",
      "1496  13  16  20  23  28  39  42  20180809\n",
      "1497   7  15  18  20  27  36  40  20180806\n",
      "1498   1  10  15  27  35  41  46  20180802\n",
      "1499   7   8  10  19  20  41  43  20180730\n",
      "1500   1   9  13  17  28  37  40  20180726\n",
      "1501   2  12  23  26  28  39  40  20180723\n",
      "1502  13  14  23  35  37  45  46  20180719\n",
      "1503   4   8  19  22  24  32  47  20180716\n",
      "1504   4  10  15  25  32  40  41  20180712\n",
      "1505   6  23  31  33  38  39  43  20180709\n",
      "1506   8  11  28  30  32  34  39  20180705\n",
      "1507  12  13  23  26  33  35  38  20180702\n",
      "1508   2   3   9  25  38  44  48  20180625\n",
      "1509   4   6  15  24  30  35  46  20180621\n",
      "1510  11  15  22  23  25  26  43  20180618\n",
      "1511   1   4  29  31  35  42  48  20180614\n",
      "1512  16  25  30  34  37  44  49  20180611\n",
      "1513  12  20  29  31  37  39  42  20180607\n",
      "1514  20  22  27  31  37  43  45  20180604\n",
      "1515  11  13  24  26  33  47  49  20180531\n",
      "1516   2   5   9  27  28  30  44  20180528\n",
      "1517  11  16  25  26  34  36  42  20180524\n",
      "1518   8  10  16  17  30  37  44  20180521\n",
      "1519   7  13  21  25  29  35  37  20180517\n",
      "1520   5  17  24  29  45  46  49  20180514\n",
      "\n",
      "[1521 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "\n",
    "mtr = MyTotoResearch(algo_no=1)\n",
    "lresult, df = mtr.load_totodata()\n",
    "\n",
    "X = mtr.modified_dataset(getAllData(df)) #\n",
    "X_Predict = mtr.get_test_data()\n",
    "test_data = getAllData(X_Predict)\n",
    "#test_data = mtr.modified_dataset(getAllData(mtr.get_test_data()))\n",
    "#X\n",
    "#print(X_Predict.head())\n",
    "\n",
    "#getSmallestN(df)\n",
    "#getBiggestN(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_best ( est, param_grid, y_c ):\n",
    "    CV_rfc = GridSearchCV(estimator=est, param_grid=param_grid, cv= 5)\n",
    "    grid_result = CV_rfc.fit(X_scaled, y_c)\n",
    "    return grid_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from itertools import product\n",
    "data = [[1,2,3],[4,5,6],[7,8,9],[10,11,23]]\n",
    "def getYLimited(oldCombination, row, col):\n",
    "    global iIndex\n",
    "    newCombination = oldCombination + str(data[row][col]) + \",\"\n",
    "    if (row == len(data) - 1):\n",
    "        q.put({\"iIndex\": iIndex, \"y_c\": [int(float(i)) for i in newCombination[0:-1].split(\",\")]})\n",
    "        if ( iIndex % 2000 == 0 ):\n",
    "            q.join()\n",
    "            print (str(int(iIndex/2000)), end=\" \")\n",
    "        iIndex = iIndex + 1\n",
    "    if (row < len(data) - 1):\n",
    "        getYLimited(newCombination, row + 1, 0);\n",
    "    if (col < len(data[row]) - 1):\n",
    "        getYLimited(oldCombination, row, col + 1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = JoinableQueue(maxsize=0)\n",
    "num_threads = 5\n",
    "\n",
    "oBestModel = { \"index\":0, \"model\": None, \"name\": None, \"accuracy\": 1 }\n",
    "oBestModelTest = { \"index\":1, \"model\": None, \"name\": None, \"accuracy\": 1 }\n",
    "oFinalModel = { \"index\":0, \"model\": None, \"name\": None, \"accuracy\": .0001, \"test_accuracy\": 1 }\n",
    "\n",
    "\n",
    "oModelMax = { }\n",
    "\n",
    "oModelMax['DTC'] = { 'accuracy': 1, 'index': 0}\n",
    "oModelMax['DTC_Test'] = { 'accuracy': 1, 'index': 0}\n",
    "\n",
    "params = {\n",
    "    'n_estimators': 10,\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 1,\n",
    "    'criterion': 'mse'\n",
    "}\n",
    "\n",
    "def predict(q):\n",
    "    while True:\n",
    "#         print(q.get())    \n",
    "#        print(iIndex)\n",
    "#        print(str(int(iIndex/2000)), end = ' ')\n",
    "#        model = DecisionTreeClassifier()\n",
    "        model = AdaBoostRegressor(GradientBoostingRegressor(**params),n_estimators=50, random_state=42) ;\n",
    "        name = \"DTC\"\n",
    "        o = q.get()\n",
    "        iIndex = o['iIndex']\n",
    "        y_c = o['y_c']\n",
    "        model.fit(X_scaled, y_c)\n",
    "        p = model.predict(X_scaled).round()\n",
    "        m_df = pd.DataFrame(index=df.index) \n",
    "        m_df['N'] = p\n",
    "    #         m_df['NU'] = np.ceil(p)\n",
    "    #         m_df['ND'] = np.floor(p)\n",
    "        p = m_df\n",
    "        bAccuracy = mtr.getAccuracyCount(np.array(p)) ;\n",
    "    #        print ( str(iIndex) + \" \" + name + \" Accuracy: \",  bAccuracy)\n",
    "        if ( oBestModel['accuracy'] < bAccuracy ):\n",
    "            oBestModel['index'] = iIndex\n",
    "            oBestModel['model'] = model\n",
    "            oBestModel['name'] = name\n",
    "            oBestModel['accuracy'] = bAccuracy\n",
    "            print ( \"Best of Best \", oBestModel['index'], oBestModel['name'], oBestModel['accuracy'] )\n",
    "        if ( oModelMax[name]['accuracy'] < bAccuracy ):\n",
    "            oModelMax[name]['accuracy'] = bAccuracy\n",
    "            oModelMax[name]['index'] = iIndex\n",
    "            oModelMax[name]['model'] = model\n",
    "            print(\"Best \", iIndex, name, oModelMax[name]['accuracy'])\n",
    "        test_result = pd.DataFrame(index=X_Predict.index)\n",
    "        test_result['T'] = X_Predict['T']\n",
    "        test_result['N' ] = model.predict(X_test_scaled).round()\n",
    "        bTestAccuracy = mtr.getAccuracyCount(np.array(test_result))        \n",
    "        if ( oBestModelTest['accuracy'] < bAccuracy ):\n",
    "            oBestModelTest['index'] = iIndex\n",
    "            oBestModelTest['model'] = model\n",
    "            oBestModelTest['name'] = name\n",
    "            oBestModelTest['accuracy'] = bAccuracy\n",
    "            print ( \"Best of Best Test \", oBestModelTest['index'], oBestModelTest['name'], oBestModelTest['accuracy'] )\n",
    "        if ( oModelMax[name + '_Test']['accuracy'] < bTestAccuracy ):\n",
    "            oModelMax[name + '_Test']['accuracy'] = bTestAccuracy\n",
    "            oModelMax[name + '_Test']['index'] = iIndex\n",
    "            oModelMax[name + '_Test']['model'] = model\n",
    "            print(\"Best Test \", iIndex, name + '_Test', oModelMax[name + '_Test']['accuracy'])\n",
    "        if ( ( oFinalModel['accuracy']+oFinalModel['test_accuracy'] ) < ( bAccuracy+bTestAccuracy ) ):\n",
    "            oFinalModel['index'] = iIndex\n",
    "            oFinalModel['model'] = model\n",
    "            oFinalModel['name'] = name\n",
    "            oFinalModel['accuracy'] = bAccuracy\n",
    "            oFinalModel['test_accuracy'] = bTestAccuracy\n",
    "            print ( \"Final Model so far \", iIndex, name, bAccuracy, bTestAccuracy )\n",
    "        q.task_done()\n",
    "\n",
    "for i in range(num_threads):\n",
    "    worker = Thread(target=predict, args=(q,))\n",
    "    worker.setDaemon(True)\n",
    "    worker.start()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result = {}\n",
    "def store_model_result(sEstimator, N, r):\n",
    "    if ( sEstimator not in model_result ):\n",
    "        model_result[sEstimator] = pd.DataFrame(index=df.index) \n",
    "    m_df = model_result[sEstimator] ;\n",
    "    m_df[N] = r\n",
    "    return m_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#of Entries:  1521\n",
      "[[  3.  10.  18. ...,  29.  36.  42.]\n",
      " [  6.   8.  22. ...,  40.  41.  45.]\n",
      " [  5.   8.  15. ...,  21.  35.  36.]\n",
      " ..., \n",
      " [  8.  10.  16. ...,  30.  37.  44.]\n",
      " [  7.  13.  21. ...,  29.  35.  37.]\n",
      " [  5.  17.  24. ...,  45.  46.  49.]]\n",
      "Best of Best  186014 DTC 11.320754716981133\n",
      "Best  186014 DTC 11.320754716981133\n",
      "Best of Best  186004 DTC 16.9811320754717\n",
      "Best  186004 DTC 16.9811320754717\n",
      "Best of Best Test  186010 DTC 11.320754716981133\n",
      "Best Test  186010 DTC_Test 11.320754716981133\n",
      "Final Model so far  186010 DTC 11.320754716981133 11.320754716981133\n",
      "Best Test  186014 DTC_Test 16.9811320754717\n",
      "Final Model so far  186014 DTC 11.320754716981133 16.9811320754717\n",
      "Best of Best  186018 DTC Best of Best Test  186004 DTC 16.9811320754717\n",
      "18.867924528301888\n",
      "Best  186018 DTC 18.867924528301888\n",
      "Final Model so far  186011 DTC 15.09433962264151 15.09433962264151\n",
      "Best of Best Test  186018 DTC 18.867924528301888\n",
      "Final Model so far  186013 DTC 18.867924528301888 13.20754716981132\n",
      "Final Model so far  186017 DTC 18.867924528301888 15.09433962264151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-5c1a22d1a366>\", line 26, in <module>\n",
      "    getYLimited(\"\",0, 0);\n",
      "  File \"<ipython-input-5-f03eee86efa7>\", line 15, in getYLimited\n",
      "    getYLimited(newCombination, row + 1, 0);\n",
      "  File \"<ipython-input-5-f03eee86efa7>\", line 15, in getYLimited\n",
      "    getYLimited(newCombination, row + 1, 0);\n",
      "  File \"<ipython-input-5-f03eee86efa7>\", line 15, in getYLimited\n",
      "    getYLimited(newCombination, row + 1, 0);\n",
      "  [Previous line repeated 1511 more times]\n",
      "  File \"<ipython-input-5-f03eee86efa7>\", line 17, in getYLimited\n",
      "    getYLimited(oldCombination, row, col + 1);\n",
      "  File \"<ipython-input-5-f03eee86efa7>\", line 15, in getYLimited\n",
      "    getYLimited(newCombination, row + 1, 0);\n",
      "  File \"<ipython-input-5-f03eee86efa7>\", line 17, in getYLimited\n",
      "    getYLimited(oldCombination, row, col + 1);\n",
      "  File \"<ipython-input-5-f03eee86efa7>\", line 17, in getYLimited\n",
      "    getYLimited(oldCombination, row, col + 1);\n",
      "  File \"<ipython-input-5-f03eee86efa7>\", line 17, in getYLimited\n",
      "    getYLimited(oldCombination, row, col + 1);\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"<ipython-input-5-f03eee86efa7>\", line 15, in getYLimited\n",
      "    getYLimited(newCombination, row + 1, 0);\n",
      "  File \"<ipython-input-5-f03eee86efa7>\", line 17, in getYLimited\n",
      "    getYLimited(oldCombination, row, col + 1);\n",
      "  File \"<ipython-input-5-f03eee86efa7>\", line 15, in getYLimited\n",
      "    getYLimited(newCombination, row + 1, 0);\n",
      "  File \"<ipython-input-5-f03eee86efa7>\", line 17, in getYLimited\n",
      "    getYLimited(oldCombination, row, col + 1);\n",
      "  File \"<ipython-input-5-f03eee86efa7>\", line 17, in getYLimited\n",
      "    getYLimited(oldCombination, row, col + 1);\n",
      "  File \"<ipython-input-5-f03eee86efa7>\", line 15, in getYLimited\n",
      "    getYLimited(newCombination, row + 1, 0);\n",
      "  File \"<ipython-input-5-f03eee86efa7>\", line 15, in getYLimited\n",
      "    getYLimited(newCombination, row + 1, 0);\n",
      "  File \"<ipython-input-5-f03eee86efa7>\", line 17, in getYLimited\n",
      "    getYLimited(oldCombination, row, col + 1);\n",
      "  File \"<ipython-input-5-f03eee86efa7>\", line 17, in getYLimited\n",
      "    getYLimited(oldCombination, row, col + 1);\n",
      "  File \"<ipython-input-5-f03eee86efa7>\", line 17, in getYLimited\n",
      "    getYLimited(oldCombination, row, col + 1);\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"<ipython-input-5-f03eee86efa7>\", line 15, in getYLimited\n",
      "    getYLimited(newCombination, row + 1, 0);\n",
      "  File \"<ipython-input-5-f03eee86efa7>\", line 17, in getYLimited\n",
      "    getYLimited(oldCombination, row, col + 1);\n",
      "  File \"<ipython-input-5-f03eee86efa7>\", line 11, in getYLimited\n",
      "    q.join()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 305, in join\n",
      "    self._cond.wait()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/synchronize.py\", line 261, in wait\n",
      "    return self._wait_semaphore.acquire(True, timeout)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/lib/python3.6/inspect.py\", line 1488, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/lib/python3.6/inspect.py\", line 1446, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/opt/conda/lib/python3.6/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/opt/conda/lib/python3.6/posixpath.py\", line 422, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/opt/conda/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "#X_scaled = X\n",
    "X_test_scaled = scaler.transform(test_data)\n",
    "\n",
    "\n",
    "l_encoder = LabelEncoder()\n",
    "result = pd.DataFrame(index=df.index)\n",
    "result['T'] = df['T']\n",
    "\n",
    "#test_data = mtr.get_test_data()\n",
    "\n",
    "y_combination = pd.DataFrame(index=df.index)\n",
    "for i in range(1,8):\n",
    "     y_combination['N'+str(i)] = df['N'+str(i)]\n",
    "#y_combination.reset_index()\n",
    "data = y_combination.values\n",
    "check_size = len(data)\n",
    "print(\"#of Entries: \", check_size)\n",
    "print(data)\n",
    "\n",
    "model_result = {}\n",
    "bBest = 0.0\n",
    "iIndex = 0\n",
    "getYLimited(\"\",0, 1);\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final Model so far   26513 DTC 20.754716981132077 28.30188679245283\n",
    "Final Model so far  114750 DTC 22.641509433962266 26.41509433962264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_printed = {}\n",
    "bBest = 0.0\n",
    "print ( \"BEST INTERSECTION\")\n",
    "for key1, value1 in model_result.items():\n",
    "    for key2, value2 in model_result.items():\n",
    "        if ( key1 != key2 )\n",
    "            if ( (key1 + key2) not in already_printed ):\n",
    "                if ( (key2 + key1) not in already_printed ) :\n",
    "                    already_printed[key1+key2] = 'Y'\n",
    "                    p = mtr.getIntersection(value1.values, value2.values)\n",
    "                    bAccuracy = mtr.getAccuracyCount(np.array(p)) ;\n",
    "                    if ( bBest < bAccuracy ):\n",
    "                        print ( key1, key2, \" Accuracy: \",  bAccuracy)\n",
    "                        bBest = bAccuracy\n",
    "                        mtr.plot_matched_counts(p)\n",
    "#                        mtr.print_predictionsV2(np.array(p))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_printed = {}\n",
    "bBest = 0.0\n",
    "print ( \"BEST UNION\")\n",
    "for key1, value1 in model_result.items():\n",
    "    for key2, value2 in model_result.items():\n",
    "        if ( key1 != key2 ):\n",
    "            if ( (key1 + key2) not in already_printed ):\n",
    "                if ( (key2 + key1) not in already_printed ) :\n",
    "                    already_printed[key1+key2] = 'Y'\n",
    "                    p = [np.union1d(a,b) for a,b in zip(value1.values, value2.values)] #mtr.getIntersection(value1.values, value2.values)\n",
    "                    bAccuracy = mtr.getAccuracyCount(np.array(p)) ;\n",
    "                    if ( bBest < bAccuracy ):\n",
    "                        print ( key1, key2, \" Accuracy: \",  bAccuracy)\n",
    "                        bBest = bAccuracy\n",
    "                        mtr.plot_matched_counts(p)\n",
    "mtr.print_predictionsV2(np.array(p))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = result.columns #['N'+str(i)+'_P' for i in range(1,8)]\n",
    "print(result.columns)\n",
    "my_prediction = pd.DataFrame(result, columns=columns)\n",
    "\n",
    "print(my_prediction)\n",
    "for col in columns:\n",
    "    my_prediction[col] = my_prediction[col].apply(lambda x: int(x) if x == x else \"\")\n",
    "    \n",
    "#print(my_prediction)\n",
    "print ( \"Accuracy: \",  mtr.getAccuracyCount(np.array(my_prediction)))\n",
    "mtr.plot_matched_counts(my_prediction.values)\n",
    "#mtr.print_result(my_prediction)\n",
    "mtr.print_predictions(my_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.unique1d(a,b) for a,b in zip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_result = np.unique(result.values)\n",
    "print(result.values)\n",
    "predicted_result = [np.unique(a) for a in result.values]\n",
    "len(predicted_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iIndex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
